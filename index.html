<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face tracker</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/face_detection.js" crossorigin="anonymous"></script>
    <style>
        #wrapper {
            position: relative;
            height: 480px;
            overflow: hidden;
        }
        #wrapper canvas, #wrapper video {
            position: absolute;
            top: 0;
            left: 0;
            z-index: 1;
            background: transparent;
            transition: transform 0.7s ease-in-out;
            transform: translateX(0);
        }
        #wrapper video {
            z-index: 0;
        }
        #wrapper canvas {
            pointer-events: none;
            z-index: 2;
        }
    </style>
</head>
<body>
    <div id="wrapper">
        <canvas id="canvas" width="640" height="480"></canvas>
        <video autoplay muted playsinline id="videoElement"></video>
    </div>
    <button id="start">start</button>
    <label>Show face boxes <input id="showboxes" type="checkbox"></label>
    <script>
        class FaceDetector {
            constructor(options = {}) {
                this.model = options.model || 'short';
                this.minDetectionConfidence = options.minDetectionConfidence || 0.6;
                this.maxNumFaces = options.maxNumFaces || 1;
                this.faceDetection = null;
                this.isInitialized = false;
                this.isDestroyed = false;
                this.initializationPromise = null;
            }

            async initialize() {
                // If already initialized or destroyed, return immediately
                if (this.isInitialized || this.isDestroyed) {
                    return;
                }

                // If initialization is already in progress, wait for it
                if (this.initializationPromise) {
                    return this.initializationPromise;
                }

                // Start initialization and store the promise
                this.initializationPromise = this._doInitialize();
                
                try {
                    await this.initializationPromise;
                } finally {
                    // Clear the promise once initialization is complete (success or failure)
                    this.initializationPromise = null;
                }
            }

            async _doInitialize() {
                try {
                    this.faceDetection = new FaceDetection({
                        locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`
                    });
                    
                    this.faceDetection.setOptions({
                        model: this.model,
                        minDetectionConfidence: this.minDetectionConfidence,
                        maxNumFaces: this.maxNumFaces,
                    });

                    this.isInitialized = true;
                    console.log('FaceDetector initialized successfully');
                } catch (error) {
                    console.error('Failed to initialize FaceDetector:', error);
                    throw error;
                }
            }

            async detect(videoElement) {
                if (!this.isInitialized) {
                    await this.initialize();
                }

                if (this.isDestroyed) {
                    throw new Error('FaceDetector has been destroyed');
                }

                return new Promise((resolve, reject) => {
                    const startTime = performance.now();
                    
                    // Set up one-time result handler
                    const onResults = (results) => {
                        const inferenceTime = performance.now() - startTime;
                        console.log(`Face detection inference time: ${inferenceTime.toFixed(2)}ms`);
                        
                        // Remove the listener to prevent memory leaks
                        this.faceDetection.onResults(() => {});
                        
                        resolve({
                            detections: results.detections || [],
                            inferenceTime: inferenceTime
                        });
                    };

                    this.faceDetection.onResults(onResults);
                    
                    // Send the video frame for detection
                    this.faceDetection.send({image: videoElement}).catch(reject);
                });
            }

            destroy() {
                if (this.faceDetection) {
                    this.faceDetection.close();
                    this.faceDetection = null;
                }
                this.isInitialized = false;
                this.isDestroyed = true;
                console.log('FaceDetector destroyed');
            }
        }

        // Configuration constants
        const DETECTION_INTERVAL_MS = 1000; // 1 second - configurable
        const VW = 640; // Video width
        const VH = 480; // Video height
        const VISIBLE_WIDTH = 300; // Wrapper width
        const MIN_EDGE_DISTANCE = 10; // px

        const TRACK_FACE = true; // Enable face tracking
        let currentPosition = 0; // Current video position
        
        const wrapper = document.getElementById('wrapper');
        wrapper.style.width = VISIBLE_WIDTH + 'px';
        const videoElement = document.getElementById('videoElement');
        videoElement.width = VW;
        videoElement.height = VH;
        const canvas = document.getElementById('canvas');
        canvas.width = VW;
        canvas.height = VH;
        
        const showBoxesCheckbox = document.getElementById('showboxes');

        moveToPosition((VISIBLE_WIDTH - VW) / 2); // Initial position

        const ctx = canvas.getContext('2d');
        const startButton = document.getElementById('start');

        const faceDetector = new FaceDetector({
            model: 'short',
            minDetectionConfidence: 0.6,
            maxNumFaces: 1
        });

        let stream;
        let detectionTimer;
        
        function getCurrentPosition() {
            return currentPosition;
        }

        function moveToPosition(position) {
            currentPosition = position;
            videoElement.style.transform = `translateX(${position}px)`;
            canvas.style.transform = `translateX(${position}px)`;
        }
        
        let detectionResults, targetDetection;

        function renderBoxes() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            if (!showBoxesCheckbox.checked || !detectionResults || !detectionResults.detections) return;

            detectionResults.detections.forEach((detection, index) => {
                const bbox = detection.boundingBox;
                const x = bbox.xCenter * canvas.width - (bbox.width * canvas.width) / 2;
                const y = bbox.yCenter * canvas.height - (bbox.height * canvas.height) / 2;
                const width = bbox.width * canvas.width;
                const height = bbox.height * canvas.height;
                
                if (detection === targetDetection) {
                    ctx.strokeStyle = 'red'; // Tracked face
                    ctx.lineWidth = 2;
                } else {
                    ctx.strokeStyle = 'orange'; // Other faces
                    ctx.lineWidth = 1;
                }
                ctx.strokeRect(x, y, width, height);
            });
        }

        showBoxesCheckbox.addEventListener('change', renderBoxes);

        function handleDetectionResults(results) {
            detectionResults = results;
            targetDetection = results.detections && results.detections.length > 0 ? results.detections[0] : null;

            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            if (results.detections && results.detections.length > 0) {
                console.log('Face detection results:', results);
                
                let targetDetection = results.detections[0];
                
                if (TRACK_FACE) {
                    if (results.detections.length > 1) {
                        const centerX = 0.5; // Center of video in normalized coordinates
                        let minDistanceToCenter = Math.abs(results.detections[0].boundingBox.xCenter - centerX);
                        
                        for (let i = 1; i < results.detections.length; i++) {
                            const distance = Math.abs(results.detections[i].boundingBox.xCenter - centerX);
                            if (distance < minDistanceToCenter) {
                                minDistanceToCenter = distance;
                                targetDetection = results.detections[i];
                            }
                        }
                        console.log(`Multiple faces detected, using closest to center (distance: ${minDistanceToCenter.toFixed(3)})`);
                    }
                    
                    // Calculate face bounding box in pixel coordinates
                    const bbox = targetDetection.boundingBox;
                    const faceX = bbox.xCenter * VW - (bbox.width * VW) / 2;
                    const faceWidth = bbox.width * VW;
                    
                    const currentLeft = getCurrentPosition();
                    
                    // Calculate face position relative to visible area
                    const faceLeftInVisible = faceX + currentLeft;
                    const faceRightInVisible = faceLeftInVisible + faceWidth;
                    
                    // Check if face is too close to edges of visible area
                    let newLeft = currentLeft;
                    
                    if (faceLeftInVisible < MIN_EDGE_DISTANCE) {
                        // Face is too close to left edge, move video right
                        newLeft = MIN_EDGE_DISTANCE - faceX;
                    } else if (faceRightInVisible > VISIBLE_WIDTH - MIN_EDGE_DISTANCE) {
                        // Face is too close to right edge, move video left
                        newLeft = (VISIBLE_WIDTH - MIN_EDGE_DISTANCE) - (faceX + faceWidth);
                    }
                    
                    // Clamp newLeft to prevent video from moving too far
                    const maxLeft = 0; // Video can't go beyond right edge
                    const minLeft = VISIBLE_WIDTH - VW; // Video can't go beyond left edge
                    newLeft = Math.max(minLeft, Math.min(maxLeft, newLeft));
                    
                    // Apply the new position if it changed
                    if (newLeft !== currentLeft) {
                        moveToPosition(newLeft);
                        console.log(`Adjusted video position: ${currentLeft}px → ${newLeft}px`);
                    }
                }
            } else {
                console.log('No faces detected - maintaining current position');
            }

            renderBoxes();
        }
        
        // Start camera and face detection
        async function startFaceTracking() {
            try {
                // Get user media stream
                stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: VW, height: VH }
                });
                
                // Set video source to the stream
                videoElement.srcObject = stream;
                
                // Wait for video to be ready
                await new Promise((resolve) => {
                    videoElement.onloadedmetadata = () => {
                        videoElement.play();
                        resolve();
                    };
                });
                
                // Start detection timer (run detection once per second)
                detectionTimer = setInterval(async () => {
                    try {
                        const results = await faceDetector.detect(videoElement);
                        handleDetectionResults(results);
                    } catch (error) {
                        console.error('Detection error:', error);
                    }
                }, DETECTION_INTERVAL_MS);
                
                startButton.textContent = 'Stop';
                startButton.onclick = stopFaceTracking;
                
                console.log('Face tracking started');
                
            } catch (error) {
                console.error('Error starting face tracking:', error);
                alert('Error accessing camera. Please make sure you have granted camera permissions.');
            }
        }
        
        // Stop face tracking
        function stopFaceTracking() {
            if (detectionTimer) {
                clearInterval(detectionTimer);
                detectionTimer = null;
            }
            
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
                videoElement.srcObject = null;
            }
            
            // Clear canvas
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            startButton.textContent = 'Start';
            startButton.onclick = startFaceTracking;
            
            console.log('Face tracking stopped');
        }
        
        // Set up start button
        startButton.onclick = startFaceTracking;
        
        // Clean up resources when page is unloaded
        window.addEventListener('beforeunload', () => {
            faceDetector.destroy();
        });
    </script>
</body>
</html>
